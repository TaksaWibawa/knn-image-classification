{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]\n",
    "n_neighbors = [3, 5, 7, 9, 11]\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(128, 128)):\n",
    "\treturn cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_features(image):\n",
    "    features = []\n",
    "    for angle in angles:\n",
    "        glcm = graycomatrix(image, [1], [angle], levels=256, symmetric=True, normed=True)\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity').ravel()\n",
    "        correlation = graycoprops(glcm, 'correlation').ravel()\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity').ravel()\n",
    "        contrast = graycoprops(glcm, 'contrast').ravel()\n",
    "        asm = graycoprops(glcm, 'ASM').ravel()\n",
    "        energy = graycoprops(glcm, 'energy').ravel()\n",
    "        angle_features = np.concatenate((dissimilarity, correlation, homogeneity, contrast, asm, energy))\n",
    "        features.extend(angle_features)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy    1536\n",
      "sad      1462\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "parent_folder = \"FacialExpression/\"\n",
    "subfolder_names = [\"happy\", \"sad\"]\n",
    "df = pd.DataFrame(columns=['Image Name', 'Category'])\n",
    "\n",
    "df_list = []\n",
    "for subfolder in subfolder_names:\n",
    "    subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "    image_list = os.listdir(subfolder_path)\n",
    "    image_names = [os.path.splitext(image)[0] for image in image_list]\n",
    "    category = [subfolder] * len(image_names)\n",
    "    image_df = pd.DataFrame(\n",
    "        {\"Image Name\": image_names, \"Category\": category})\n",
    "    df_list.append(image_df)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 9/2998\n",
      "[INFO] processed 200/2998\n",
      "[INFO] processed 400/2998\n",
      "[INFO] processed 600/2998\n",
      "[INFO] processed 800/2998\n",
      "File corrupted: happy-0974\n",
      "[INFO] processed 1000/2998\n",
      "[INFO] processed 1200/2998\n",
      "[INFO] processed 1400/2998\n",
      "[INFO] processed 1600/2998\n",
      "[INFO] processed 1800/2998\n",
      "[INFO] processed 2000/2998\n",
      "[INFO] processed 2200/2998\n",
      "[INFO] processed 2400/2998\n",
      "File corrupted: sad-0967\n",
      "[INFO] processed 2600/2998\n",
      "[INFO] processed 2800/2998\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(df['Image Name']):\n",
    "    label = df['Category'][i]\n",
    "    path = os.path.join(parent_folder, label + '/' + imagePath + \".jpg\")\n",
    "    try:\n",
    "        #read image in grayscale and resize it to be 1:1\n",
    "        image = cv2.imread(path, 0)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        pixels = image_to_feature_vector(image)\n",
    "        feat = extract_features(image)\n",
    "        rawImages.append(pixels)\n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "    except:\n",
    "        print(\"File corrupted: {}\".format(imagePath))\n",
    "\n",
    "    # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1)% 200 == 0 or i == len(imagePath)-2):\n",
    "\t    print(\"[INFO] processed {}/{}\".format(i+1, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 47.94MB\n",
      "[INFO] features matrix: 0.70MB\n"
     ]
    }
   ],
   "source": [
    "rawImages = np.array(rawImages)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
    "\trawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(\n",
    "\tfeatures.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide 1537 happy and 1463 sad images into equal amount for training and testing using sklearn by 80 20\n",
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "\trawImages, labels, test_size=0.15, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy for k=3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] k-NN classifier: k=3\n",
      "[INFO] raw pixel accuracy: 61.78%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.62      0.64      0.63       230\n",
      "         sad       0.61      0.60      0.60       220\n",
      "\n",
      "    accuracy                           0.62       450\n",
      "   macro avg       0.62      0.62      0.62       450\n",
      "weighted avg       0.62      0.62      0.62       450\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=5...\n",
      "[INFO] k-NN classifier: k=5\n",
      "[INFO] raw pixel accuracy: 64.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.65      0.65      0.65       230\n",
      "         sad       0.63      0.63      0.63       220\n",
      "\n",
      "    accuracy                           0.64       450\n",
      "   macro avg       0.64      0.64      0.64       450\n",
      "weighted avg       0.64      0.64      0.64       450\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=7...\n",
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] raw pixel accuracy: 67.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.67      0.70      0.69       230\n",
      "         sad       0.67      0.64      0.66       220\n",
      "\n",
      "    accuracy                           0.67       450\n",
      "   macro avg       0.67      0.67      0.67       450\n",
      "weighted avg       0.67      0.67      0.67       450\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=9...\n",
      "[INFO] k-NN classifier: k=9\n",
      "[INFO] raw pixel accuracy: 66.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.66      0.70      0.68       230\n",
      "         sad       0.67      0.63      0.65       220\n",
      "\n",
      "    accuracy                           0.67       450\n",
      "   macro avg       0.67      0.67      0.67       450\n",
      "weighted avg       0.67      0.67      0.67       450\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=11...\n",
      "[INFO] k-NN classifier: k=11\n",
      "[INFO] raw pixel accuracy: 66.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.66      0.71      0.68       230\n",
      "         sad       0.67      0.62      0.65       220\n",
      "\n",
      "    accuracy                           0.67       450\n",
      "   macro avg       0.67      0.67      0.67       450\n",
      "weighted avg       0.67      0.67      0.67       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel = None\n",
    "bestAcc = 0.0\n",
    "k1 = 0\n",
    "for (i, k) in enumerate(n_neighbors):\n",
    "    print(\"[INFO] evaluating raw pixel accuracy for k={}...\".format(k))\n",
    "    model = KNeighborsClassifier(n_neighbors=k, weights=\"distance\", n_jobs=-1)\n",
    "    model.fit(trainRI, trainRL)\n",
    "    pred_raw = model.predict(testRI)\n",
    "    acc = accuracy_score(testRL, pred_raw)\n",
    "\n",
    "    print(\"[INFO] k-NN classifier: k={}\".format(k))\n",
    "    print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc*100))\n",
    "    report = classification_report(testRL, pred_raw, target_names=[\"happy\", \"sad\"])\n",
    "    print(report)\n",
    "\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc\n",
    "        bestModel = model\n",
    "        k1 = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating feature accuracy for k=3...\n",
      "[INFO] k-NN classifier: k=3\n",
      "[INFO] feature accuracy: 55.11%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.60      0.58       230\n",
      "         sad       0.55      0.50      0.52       220\n",
      "\n",
      "    accuracy                           0.55       450\n",
      "   macro avg       0.55      0.55      0.55       450\n",
      "weighted avg       0.55      0.55      0.55       450\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=5...\n",
      "[INFO] k-NN classifier: k=5\n",
      "[INFO] feature accuracy: 53.11%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.54      0.60      0.57       230\n",
      "         sad       0.52      0.46      0.49       220\n",
      "\n",
      "    accuracy                           0.53       450\n",
      "   macro avg       0.53      0.53      0.53       450\n",
      "weighted avg       0.53      0.53      0.53       450\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=7...\n",
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] feature accuracy: 52.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.53      0.60      0.56       230\n",
      "         sad       0.52      0.45      0.48       220\n",
      "\n",
      "    accuracy                           0.53       450\n",
      "   macro avg       0.53      0.53      0.52       450\n",
      "weighted avg       0.53      0.53      0.52       450\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=9...\n",
      "[INFO] k-NN classifier: k=9\n",
      "[INFO] feature accuracy: 54.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.55      0.60      0.57       230\n",
      "         sad       0.53      0.48      0.50       220\n",
      "\n",
      "    accuracy                           0.54       450\n",
      "   macro avg       0.54      0.54      0.54       450\n",
      "weighted avg       0.54      0.54      0.54       450\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=11...\n",
      "[INFO] k-NN classifier: k=11\n",
      "[INFO] feature accuracy: 53.56%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.54      0.58      0.56       230\n",
      "         sad       0.53      0.49      0.51       220\n",
      "\n",
      "    accuracy                           0.54       450\n",
      "   macro avg       0.53      0.53      0.53       450\n",
      "weighted avg       0.53      0.54      0.53       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel2 = None\n",
    "bestAcc2 = 0.0\n",
    "k2 = 0\n",
    "for k in n_neighbors:\n",
    "    print(\"[INFO] evaluating feature accuracy for k={}...\".format(k))\n",
    "    model = KNeighborsClassifier(n_neighbors=k, weights=\"distance\", n_jobs=-1)\n",
    "    model.fit(trainFeat, trainLabels)\n",
    "    pred_feat = model.predict(testFeat)\n",
    "    acc = accuracy_score(testLabels, pred_feat)\n",
    "\n",
    "    print(\"[INFO] k-NN classifier: k={}\".format(k))\n",
    "    print(\"[INFO] feature accuracy: {:.2f}%\".format(acc*100))\n",
    "    report = classification_report(testLabels, pred_feat, target_names=[\"happy\", \"sad\"])\n",
    "    print(report)\n",
    "\n",
    "    if acc > bestAcc2:\n",
    "        bestAcc2 = acc\n",
    "        bestModel2 = model\n",
    "        k2 = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] feature accuracy image model: 66.67%\n",
      "Image 1 is ['happy']\n",
      "Image 2 is ['happy']\n"
     ]
    }
   ],
   "source": [
    "img = \"sad-0031.jpg\"\n",
    "img2 = \"happy-0078.jpg\"\n",
    "img_gray = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2GRAY)\n",
    "img_gray2 = cv2.cvtColor(cv2.imread(img2), cv2.COLOR_BGR2GRAY)\n",
    "feat = image_to_feature_vector(img_gray)\n",
    "feat2 = image_to_feature_vector(img_gray2)\n",
    "\n",
    "pred_img = bestModel.predict([feat])\n",
    "pred_img2 = bestModel.predict([feat2])\n",
    "\n",
    "acc = accuracy_score(testRL, pred_raw)\n",
    "\n",
    "print(\"[INFO] k-NN classifier: k={}\".format(k1))\n",
    "print(\"[INFO] feature accuracy image model: {:.2f}%\".format(acc*100))\n",
    "\n",
    "print(\"Image 1 is {}\".format(pred_img))\n",
    "print(\"Image 2 is {}\".format(pred_img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] k-NN classifier: k=3\n",
      "[INFO] feature accuracy image model: 53.56%\n",
      "Image 1 is ['sad']\n",
      "Image 2 is ['sad']\n"
     ]
    }
   ],
   "source": [
    "img = \"sad-0031.jpg\"\n",
    "img2 = \"happy-0078.jpg\"\n",
    "img_gray = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2GRAY)\n",
    "img_gray2 = cv2.cvtColor(cv2.imread(img2), cv2.COLOR_BGR2GRAY)\n",
    "feat = extract_features(img_gray)\n",
    "feat2 = extract_features(img_gray2)\n",
    "\n",
    "pred_img = bestModel2.predict([feat])\n",
    "pred_img2 = bestModel2.predict([feat2])\n",
    "\n",
    "acc = accuracy_score(testLabels, pred_feat)\n",
    "\n",
    "print(\"[INFO] k-NN classifier: k={}\".format(k2))\n",
    "print(\"[INFO] feature accuracy image model: {:.2f}%\".format(acc*100))\n",
    "\n",
    "print(\"Image 1 is {}\".format(pred_img))\n",
    "print(\"Image 2 is {}\".format(pred_img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"knn_model.sav\"\n",
    "pickle.dump(bestModel2, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
