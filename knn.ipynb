{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library and Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]\n",
    "n_neighbors = [1, 3, 5, 7, 9]\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Preprocessing and Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize image while maintaining aspect ratio\n",
    "    height, width = grayscale_image.shape[:2]\n",
    "    if height > width:\n",
    "        new_height = target_size\n",
    "        new_width = int(width * (target_size / height))\n",
    "    else:\n",
    "        new_width = target_size\n",
    "        new_height = int(height * (target_size / width))\n",
    "    resized_image = cv2.resize(grayscale_image, (new_width, new_height))\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = []\n",
    "    for angle in angles:\n",
    "        glcm = graycomatrix(image, [1], [angle], levels=256, symmetric=True, normed=True)\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity').ravel()\n",
    "        correlation = graycoprops(glcm, 'correlation').ravel()\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity').ravel()\n",
    "        contrast = graycoprops(glcm, 'contrast').ravel()\n",
    "        asm = graycoprops(glcm, 'ASM').ravel()\n",
    "        energy = graycoprops(glcm, 'energy').ravel()\n",
    "        angle_features = np.concatenate((dissimilarity, correlation, homogeneity, contrast, asm, energy))\n",
    "        features.append(angle_features)\n",
    "\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read Image Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy    1537\n",
      "sad      1463\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "parent_folder = \"FacialExpression/\"\n",
    "subfolder_names = [\"happy\", \"sad\"]\n",
    "df = pd.DataFrame(columns=['Image Name', 'Category'])\n",
    "\n",
    "df_list = []\n",
    "for subfolder in subfolder_names:\n",
    "    subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "    image_list = os.listdir(subfolder_path)\n",
    "    image_names = [os.path.splitext(image)[0] for image in image_list]\n",
    "    category = [subfolder] * len(image_names)\n",
    "    image_df = pd.DataFrame(\n",
    "        {\"Image Name\": image_names, \"Category\": category})\n",
    "    df_list.append(image_df)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Process The Image\n",
    "### a. Change Category Data (happy and sad) to Numeric Data (0 and 1)\n",
    "### b. Resize Image to with either height as 128 or width as 128 based on it's aspect ratio\n",
    "### c. Extract Features from Image using Feature Extraction Function with GLCM (Total 30 Features)\n",
    "### d. Append Its Features and Label into List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10/3000\n",
      "[INFO] processed 200/3000\n",
      "[INFO] processed 400/3000\n",
      "[INFO] processed 600/3000\n",
      "[INFO] processed 800/3000\n",
      "File corrupted: happy-0974\n",
      "[INFO] processed 1000/3000\n",
      "[INFO] processed 1200/3000\n",
      "[INFO] processed 1400/3000\n",
      "[INFO] processed 1600/3000\n",
      "[INFO] processed 1800/3000\n",
      "[INFO] processed 2000/3000\n",
      "[INFO] processed 2200/3000\n",
      "[INFO] processed 2400/3000\n",
      "File corrupted: sad-0967\n",
      "[INFO] processed 2600/3000\n",
      "[INFO] processed 2800/3000\n",
      "[INFO] processed 3000/3000\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(df['Image Name']):\n",
    "    if df['Category'][i] == \"happy\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1 #sad\n",
    "    path = os.path.join(parent_folder, df[\"Category\"][i] + '/' + imagePath + \".jpg\")\n",
    "    try:\n",
    "        image = preprocess_image(path, 128)\n",
    "        feat = extract_features(image)\n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "    except:\n",
    "        print(\"File corrupted: {}\".format(imagePath))\n",
    "\n",
    "    # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1)% 200 == 0 or i == len(imagePath)-1):\n",
    "\t    print(\"[INFO] processed {}/{}\".format(i+1, len(df)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Split Data into Training and Testing Data (80% Training and 20% Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide 1537 happy and 1463 sad images into equal amount for training and testing using sklearn by 80 20\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train Model\n",
    "### a. Enumerate K based on what we initialize before to find the best model\n",
    "### b. Create Model with K Nearest Neighbor Classifier\n",
    "### c. Train Model with Training Data\n",
    "### d. Predict Label of Testing Data\n",
    "### e. Calculate Accuracy of Model\n",
    "### f. Save the Model with Highest Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating feature accuracy for k=1...\n",
      "[INFO] k-NN classifier: k=1\n",
      "[INFO] feature accuracy: 48.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.52      0.49      0.50       321\n",
      "         sad       0.45      0.48      0.46       279\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.48      0.48      0.48       600\n",
      "weighted avg       0.48      0.48      0.48       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=3...\n",
      "[INFO] k-NN classifier: k=3\n",
      "[INFO] feature accuracy: 49.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.53      0.50      0.52       321\n",
      "         sad       0.46      0.50      0.48       279\n",
      "\n",
      "    accuracy                           0.50       600\n",
      "   macro avg       0.50      0.50      0.50       600\n",
      "weighted avg       0.50      0.50      0.50       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=5...\n",
      "[INFO] k-NN classifier: k=5\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.57      0.57       321\n",
      "         sad       0.49      0.48      0.49       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=7...\n",
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.55      0.56       321\n",
      "         sad       0.49      0.50      0.50       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=9...\n",
      "[INFO] k-NN classifier: k=9\n",
      "[INFO] feature accuracy: 53.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.59      0.58       321\n",
      "         sad       0.50      0.47      0.49       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.54      0.54      0.54       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel2 = None\n",
    "bestAcc2 = 0.0\n",
    "k2 = 0\n",
    "for k in n_neighbors:\n",
    "    print(\"[INFO] evaluating feature accuracy for k={}...\".format(k))\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainFeat, trainLabels)\n",
    "    pred_feat = model.predict(testFeat)\n",
    "    acc = accuracy_score(testLabels, pred_feat)\n",
    "\n",
    "    print(\"[INFO] k-NN classifier: k={}\".format(k))\n",
    "    print(\"[INFO] feature accuracy: {:.2f}%\".format(acc*100))\n",
    "    report = classification_report(testLabels, pred_feat, target_names=[\"happy\", \"sad\"])\n",
    "    print(report)\n",
    "\n",
    "    if acc > bestAcc2:\n",
    "        bestAcc2 = acc\n",
    "        bestModel2 = model\n",
    "        k2 = k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"knn_model.sav\"\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. If Necessary, Do Hyperparameter Tuning Based on 2 Parameter Used in KNN\n",
    "### a. n_neighbors \n",
    "### b. p (1 = manhattan_distance, 2 = euclidean_distance) for Minkowski Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best p: 1\n",
      "Best n_neighbors: 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "n_neighbors = list(range(1,30,2))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters)\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(trainFeat, trainLabels)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>55.505828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>55.422147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>55.297408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>55.130045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>55.088118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>55.047147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>55.046886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>55.046625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>55.046625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>54.963553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>54.963118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>54.881176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>54.753914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>54.588118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>54.421190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>54.338031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>54.337944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>54.336900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>54.296451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.295146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>54.254610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>54.254523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>54.212074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.170233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>54.087596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>54.004175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53.962335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53.879088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>53.253740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53.085421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_neighbors param_p   accuracy\n",
       "22                23       1  55.505828\n",
       "5                  5       2  55.422147\n",
       "24                25       1  55.297408\n",
       "8                  9       1  55.130045\n",
       "6                  7       1  55.088118\n",
       "19                19       2  55.047147\n",
       "25                25       2  55.046886\n",
       "13                13       2  55.046625\n",
       "18                19       1  55.046625\n",
       "16                17       1  54.963553\n",
       "27                27       2  54.963118\n",
       "17                17       2  54.881176\n",
       "7                  7       2  54.753914\n",
       "29                29       2  54.588118\n",
       "20                21       1  54.421190\n",
       "4                  5       1  54.338031\n",
       "10                11       1  54.337944\n",
       "9                  9       2  54.336900\n",
       "14                15       1  54.296451\n",
       "1                  1       2  54.295146\n",
       "15                15       2  54.254610\n",
       "28                29       1  54.254523\n",
       "11                11       2  54.212074\n",
       "0                  1       1  54.170233\n",
       "23                23       2  54.087596\n",
       "21                21       2  54.004175\n",
       "12                13       1  53.962335\n",
       "2                  3       1  53.879088\n",
       "26                27       1  53.253740\n",
       "3                  3       2  53.085421"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(clf.cv_results_)\n",
    "#show accuracy for each combination of parameters\n",
    "results['accuracy'] = results['mean_test_score'].apply(lambda x: x*100)\n",
    "sorted_result = results[['param_n_neighbors', 'param_p', 'accuracy']]\n",
    "sorted_result.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_result.to_excel(\"knn_gridsearch.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating feature accuracy for k=5...\n",
      "[INFO] k-NN classifier: k=5\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.57      0.57       321\n",
      "         sad       0.49      0.48      0.49       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating feature accuracy for k={}...\".format(5))\n",
    "model = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "model.fit(trainFeat, trainLabels)\n",
    "pred_feat = model.predict(testFeat)\n",
    "acc = accuracy_score(testLabels, pred_feat)\n",
    "print(\"[INFO] k-NN classifier: k={}\".format(5))\n",
    "print(\"[INFO] feature accuracy: {:.2f}%\".format(acc*100))\n",
    "report = classification_report(testLabels, pred_feat, target_names=[\"happy\", \"sad\"])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
