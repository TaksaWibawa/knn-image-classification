{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library and Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]\n",
    "n_neighbors = [1, 3, 5, 7, 9]\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Preprocessing and Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize image while maintaining aspect ratio\n",
    "    height, width = grayscale_image.shape[:2]\n",
    "    if height > width:\n",
    "        new_height = target_size\n",
    "        new_width = int(width * (target_size / height))\n",
    "    else:\n",
    "        new_width = target_size\n",
    "        new_height = int(height * (target_size / width))\n",
    "    resized_image = cv2.resize(grayscale_image, (new_width, new_height))\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = []\n",
    "    for angle in angles:\n",
    "        glcm = graycomatrix(image, [1], [angle], levels=256, symmetric=True, normed=True)\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity').ravel()\n",
    "        correlation = graycoprops(glcm, 'correlation').ravel()\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity').ravel()\n",
    "        contrast = graycoprops(glcm, 'contrast').ravel()\n",
    "        asm = graycoprops(glcm, 'ASM').ravel()\n",
    "        energy = graycoprops(glcm, 'energy').ravel()\n",
    "        angle_features = np.concatenate((dissimilarity, correlation, homogeneity, contrast, asm, energy))\n",
    "        features.append(angle_features)\n",
    "\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read Image Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy    1537\n",
      "sad      1463\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "parent_folder = \"FacialExpression/\"\n",
    "subfolder_names = [\"happy\", \"sad\"]\n",
    "df = pd.DataFrame(columns=['Image Name', 'Category'])\n",
    "\n",
    "df_list = []\n",
    "for subfolder in subfolder_names:\n",
    "    subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "    image_list = os.listdir(subfolder_path)\n",
    "    image_names = [os.path.splitext(image)[0] for image in image_list]\n",
    "    category = [subfolder] * len(image_names)\n",
    "    image_df = pd.DataFrame(\n",
    "        {\"Image Name\": image_names, \"Category\": category})\n",
    "    df_list.append(image_df)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Process The Image\n",
    "### a. Change Category Data (happy and sad) to Numeric Data (0 and 1)\n",
    "### b. Resize Image to with either height as 128 or width as 128 based on it's aspect ratio\n",
    "### c. Extract Features from Image using Feature Extraction Function with GLCM (Total 30 Features)\n",
    "### d. Append Its Features and Label into List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10/3000\n",
      "[INFO] processed 200/3000\n",
      "[INFO] processed 400/3000\n",
      "[INFO] processed 600/3000\n",
      "[INFO] processed 800/3000\n",
      "File corrupted: happy-0974\n",
      "[INFO] processed 1000/3000\n",
      "[INFO] processed 1200/3000\n",
      "[INFO] processed 1400/3000\n",
      "[INFO] processed 1600/3000\n",
      "[INFO] processed 1800/3000\n",
      "[INFO] processed 2000/3000\n",
      "[INFO] processed 2200/3000\n",
      "[INFO] processed 2400/3000\n",
      "File corrupted: sad-0967\n",
      "[INFO] processed 2600/3000\n",
      "[INFO] processed 2800/3000\n",
      "[INFO] processed 3000/3000\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(df['Image Name']):\n",
    "    if df['Category'][i] == \"happy\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1 #sad\n",
    "    path = os.path.join(parent_folder, df[\"Category\"][i] + '/' + imagePath + \".jpg\")\n",
    "    try:\n",
    "        image = preprocess_image(path, 128)\n",
    "        feat = extract_features(image)\n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "    except:\n",
    "        print(\"File corrupted: {}\".format(imagePath))\n",
    "\n",
    "    # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1)% 200 == 0 or i == len(imagePath)-1):\n",
    "\t    print(\"[INFO] processed {}/{}\".format(i+1, len(df)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Split Data into Training and Testing Data (80% Training and 20% Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide 1537 happy and 1463 sad images into equal amount for training and testing using sklearn by 80 20\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train Model\n",
    "### a. Enumerate K based on what we initialize before to find the best model\n",
    "### b. Create Model with K Nearest Neighbor Classifier\n",
    "### c. Train Model with Training Data\n",
    "### d. Predict Label of Testing Data\n",
    "### e. Calculate Accuracy of Model\n",
    "### f. Save the Model with Highest Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating feature accuracy for k=1...\n",
      "[INFO] k-NN classifier: k=1\n",
      "[INFO] feature accuracy: 48.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.52      0.49      0.50       321\n",
      "         sad       0.45      0.48      0.46       279\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.48      0.48      0.48       600\n",
      "weighted avg       0.48      0.48      0.48       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=3...\n",
      "[INFO] k-NN classifier: k=3\n",
      "[INFO] feature accuracy: 49.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.53      0.50      0.52       321\n",
      "         sad       0.46      0.50      0.48       279\n",
      "\n",
      "    accuracy                           0.50       600\n",
      "   macro avg       0.50      0.50      0.50       600\n",
      "weighted avg       0.50      0.50      0.50       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=5...\n",
      "[INFO] k-NN classifier: k=5\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.57      0.57       321\n",
      "         sad       0.49      0.48      0.49       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=7...\n",
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.55      0.56       321\n",
      "         sad       0.49      0.50      0.50       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=9...\n",
      "[INFO] k-NN classifier: k=9\n",
      "[INFO] feature accuracy: 53.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.59      0.58       321\n",
      "         sad       0.50      0.47      0.49       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.54      0.54      0.54       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel2 = None\n",
    "bestAcc2 = 0.0\n",
    "k2 = 0\n",
    "for k in n_neighbors:\n",
    "    print(\"[INFO] evaluating feature accuracy for k={}...\".format(k))\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainFeat, trainLabels)\n",
    "    pred_feat = model.predict(testFeat)\n",
    "    acc = accuracy_score(testLabels, pred_feat)\n",
    "\n",
    "    print(\"[INFO] k-NN classifier: k={}\".format(k))\n",
    "    print(\"[INFO] feature accuracy: {:.2f}%\".format(acc*100))\n",
    "    report = classification_report(testLabels, pred_feat, target_names=[\"happy\", \"sad\"])\n",
    "    print(report)\n",
    "\n",
    "    if acc > bestAcc2:\n",
    "        bestAcc2 = acc\n",
    "        bestModel2 = model\n",
    "        k2 = k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"knn_model.sav\"\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. If Necessary, Do Hyperparameter Tuning Based on 3 Parameter Used in KNN\n",
    "### a. n_neighbors\n",
    "### b. leaf_size\n",
    "### c. p (1 = manhattan_distance, 2 = euclidean_distance) for Minkowski Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best p: 1\n",
      "Best n_neighbors: 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30,2))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters)\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(trainFeat, trainLabels)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_leaf_size</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>55.505828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>55.505828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>55.505828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>55.505828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>55.505828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53.085421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53.085421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53.085421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53.085421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53.085421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_leaf_size param_n_neighbors param_p   accuracy\n",
       "172                6                23       1  55.505828\n",
       "1402              47                23       1  55.505828\n",
       "652               22                23       1  55.505828\n",
       "232                8                23       1  55.505828\n",
       "802               27                23       1  55.505828\n",
       "...              ...               ...     ...        ...\n",
       "423               15                 3       2  53.085421\n",
       "1263              43                 3       2  53.085421\n",
       "453               16                 3       2  53.085421\n",
       "483               17                 3       2  53.085421\n",
       "1233              42                 3       2  53.085421\n",
       "\n",
       "[1470 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(clf.cv_results_)\n",
    "#show accuracy for each combination of parameters\n",
    "results['accuracy'] = results['mean_test_score'].apply(lambda x: x*100)\n",
    "results[['param_leaf_size', 'param_n_neighbors', 'param_p', 'accuracy']].sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel(\"knn_gridsearch.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating feature accuracy for k=23...\n",
      "[INFO] k-NN classifier: k=23\n",
      "[INFO] feature accuracy: 54.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.61      0.59       321\n",
      "         sad       0.52      0.48      0.50       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.55      0.55      0.55       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating feature accuracy for k={}...\".format(23))\n",
    "model = KNeighborsClassifier(n_neighbors=23, leaf_size=6)\n",
    "model.fit(trainFeat, trainLabels)\n",
    "pred_feat = model.predict(testFeat)\n",
    "acc = accuracy_score(testLabels, pred_feat)\n",
    "print(\"[INFO] k-NN classifier: k={}\".format(23))\n",
    "print(\"[INFO] feature accuracy: {:.2f}%\".format(acc*100))\n",
    "report = classification_report(testLabels, pred_feat, target_names=[\"happy\", \"sad\"])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
