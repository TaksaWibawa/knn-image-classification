{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]\n",
    "n_neighbors = [1, 3, 5, 7, 9, 11]\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize image while maintaining aspect ratio\n",
    "    height, width = grayscale_image.shape[:2]\n",
    "    if height > width:\n",
    "        new_height = target_size\n",
    "        new_width = int(width * (target_size / height))\n",
    "    else:\n",
    "        new_width = target_size\n",
    "        new_height = int(height * (target_size / width))\n",
    "    resized_image = cv2.resize(grayscale_image, (new_width, new_height))\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "def extract_features(image):\n",
    "    features = []\n",
    "    for angle in angles:\n",
    "        glcm = graycomatrix(image, [1], [angle], levels=256, symmetric=True, normed=True)\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity').ravel()\n",
    "        correlation = graycoprops(glcm, 'correlation').ravel()\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity').ravel()\n",
    "        contrast = graycoprops(glcm, 'contrast').ravel()\n",
    "        asm = graycoprops(glcm, 'ASM').ravel()\n",
    "        energy = graycoprops(glcm, 'energy').ravel()\n",
    "        angle_features = np.concatenate((dissimilarity, correlation, homogeneity, contrast, asm, energy))\n",
    "        features.append(angle_features)\n",
    "\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy    1537\n",
      "sad      1463\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "parent_folder = \"FacialExpression/\"\n",
    "subfolder_names = [\"happy\", \"sad\"]\n",
    "df = pd.DataFrame(columns=['Image Name', 'Category'])\n",
    "\n",
    "df_list = []\n",
    "for subfolder in subfolder_names:\n",
    "    subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "    image_list = os.listdir(subfolder_path)\n",
    "    image_names = [os.path.splitext(image)[0] for image in image_list]\n",
    "    category = [subfolder] * len(image_names)\n",
    "    image_df = pd.DataFrame(\n",
    "        {\"Image Name\": image_names, \"Category\": category})\n",
    "    df_list.append(image_df)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(df['Category'].value_counts())\n",
    "\n",
    "#Output\n",
    "#happy    1537\n",
    "#sad      1463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10/3000\n",
      "[INFO] processed 200/3000\n",
      "[INFO] processed 400/3000\n",
      "[INFO] processed 600/3000\n",
      "[INFO] processed 800/3000\n",
      "File corrupted: happy-0974\n",
      "[INFO] processed 1000/3000\n",
      "[INFO] processed 1200/3000\n",
      "[INFO] processed 1400/3000\n",
      "[INFO] processed 1600/3000\n",
      "[INFO] processed 1800/3000\n",
      "[INFO] processed 2000/3000\n",
      "[INFO] processed 2200/3000\n",
      "[INFO] processed 2400/3000\n",
      "File corrupted: sad-0967\n",
      "[INFO] processed 2600/3000\n",
      "[INFO] processed 2800/3000\n",
      "[INFO] processed 3000/3000\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(df['Image Name']):\n",
    "    if df['Category'][i] == \"happy\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    path = os.path.join(parent_folder, df[\"Category\"][i] + '/' + imagePath + \".jpg\")\n",
    "    try:\n",
    "        image = preprocess_image(path, 128)\n",
    "        feat = extract_features(image)\n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "    except:\n",
    "        print(\"File corrupted: {}\".format(imagePath))\n",
    "\n",
    "    # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1)% 200 == 0 or i == len(imagePath)-1):\n",
    "\t    print(\"[INFO] processed {}/{}\".format(i+1, len(df)))\n",
    "            \n",
    "#Output\n",
    "# [INFO] processed 10/3000\n",
    "# [INFO] processed 200/3000\n",
    "# [INFO] processed 400/3000\n",
    "# [INFO] processed 600/3000\n",
    "# [INFO] processed 800/3000\n",
    "# File corrupted: happy-0974\n",
    "# [INFO] processed 1000/3000\n",
    "# [INFO] processed 1200/3000\n",
    "# [INFO] processed 1400/3000\n",
    "# [INFO] processed 1600/3000\n",
    "# [INFO] processed 1800/3000\n",
    "# [INFO] processed 2000/3000\n",
    "# [INFO] processed 2200/3000\n",
    "# [INFO] processed 2400/3000\n",
    "# File corrupted: sad-0967\n",
    "# [INFO] processed 2600/3000\n",
    "# [INFO] processed 2800/3000\n",
    "# [INFO] processed 3000/3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide 1537 happy and 1463 sad images into equal amount for training and testing using sklearn by 80 20\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating feature accuracy for k=1...\n",
      "[INFO] k-NN classifier: k=1\n",
      "[INFO] feature accuracy: 48.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.52      0.49      0.50       321\n",
      "         sad       0.45      0.48      0.46       279\n",
      "\n",
      "    accuracy                           0.48       600\n",
      "   macro avg       0.48      0.48      0.48       600\n",
      "weighted avg       0.48      0.48      0.48       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=2...\n",
      "[INFO] k-NN classifier: k=2\n",
      "[INFO] feature accuracy: 51.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.53      0.76      0.63       321\n",
      "         sad       0.45      0.23      0.30       279\n",
      "\n",
      "    accuracy                           0.51       600\n",
      "   macro avg       0.49      0.49      0.47       600\n",
      "weighted avg       0.50      0.51      0.48       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=3...\n",
      "[INFO] k-NN classifier: k=3\n",
      "[INFO] feature accuracy: 49.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.53      0.50      0.52       321\n",
      "         sad       0.46      0.50      0.48       279\n",
      "\n",
      "    accuracy                           0.50       600\n",
      "   macro avg       0.50      0.50      0.50       600\n",
      "weighted avg       0.50      0.50      0.50       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=4...\n",
      "[INFO] k-NN classifier: k=4\n",
      "[INFO] feature accuracy: 52.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.54      0.73      0.62       321\n",
      "         sad       0.48      0.29      0.36       279\n",
      "\n",
      "    accuracy                           0.52       600\n",
      "   macro avg       0.51      0.51      0.49       600\n",
      "weighted avg       0.51      0.52      0.50       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=5...\n",
      "[INFO] k-NN classifier: k=5\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.57      0.57       321\n",
      "         sad       0.49      0.48      0.49       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=6...\n",
      "[INFO] k-NN classifier: k=6\n",
      "[INFO] feature accuracy: 52.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.55      0.71      0.62       321\n",
      "         sad       0.49      0.32      0.39       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.52      0.51      0.50       600\n",
      "weighted avg       0.52      0.53      0.51       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=7...\n",
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.55      0.56       321\n",
      "         sad       0.49      0.50      0.50       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.53      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=8...\n",
      "[INFO] k-NN classifier: k=8\n",
      "[INFO] feature accuracy: 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.55      0.69      0.61       321\n",
      "         sad       0.49      0.35      0.41       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.52      0.52      0.51       600\n",
      "weighted avg       0.52      0.53      0.52       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=9...\n",
      "[INFO] k-NN classifier: k=9\n",
      "[INFO] feature accuracy: 53.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.59      0.58       321\n",
      "         sad       0.50      0.47      0.49       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.54      0.54      0.54       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=10...\n",
      "[INFO] k-NN classifier: k=10\n",
      "[INFO] feature accuracy: 56.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.58      0.71      0.64       321\n",
      "         sad       0.55      0.40      0.46       279\n",
      "\n",
      "    accuracy                           0.57       600\n",
      "   macro avg       0.56      0.56      0.55       600\n",
      "weighted avg       0.56      0.57      0.56       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=11...\n",
      "[INFO] k-NN classifier: k=11\n",
      "[INFO] feature accuracy: 54.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.60      0.58       321\n",
      "         sad       0.51      0.48      0.50       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.54      0.55      0.54       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=12...\n",
      "[INFO] k-NN classifier: k=12\n",
      "[INFO] feature accuracy: 53.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.55      0.68      0.61       321\n",
      "         sad       0.50      0.38      0.43       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.52       600\n",
      "weighted avg       0.53      0.54      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=13...\n",
      "[INFO] k-NN classifier: k=13\n",
      "[INFO] feature accuracy: 54.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.60      0.58       321\n",
      "         sad       0.51      0.49      0.50       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.55      0.55      0.55       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=14...\n",
      "[INFO] k-NN classifier: k=14\n",
      "[INFO] feature accuracy: 54.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.67      0.61       321\n",
      "         sad       0.51      0.39      0.45       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.54      0.53      0.53       600\n",
      "weighted avg       0.54      0.54      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=15...\n",
      "[INFO] k-NN classifier: k=15\n",
      "[INFO] feature accuracy: 54.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.60      0.58       321\n",
      "         sad       0.51      0.47      0.49       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.54      0.54      0.53       600\n",
      "weighted avg       0.54      0.54      0.54       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=16...\n",
      "[INFO] k-NN classifier: k=16\n",
      "[INFO] feature accuracy: 53.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.68      0.61       321\n",
      "         sad       0.50      0.38      0.43       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.52       600\n",
      "weighted avg       0.53      0.54      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=17...\n",
      "[INFO] k-NN classifier: k=17\n",
      "[INFO] feature accuracy: 54.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.59      0.58       321\n",
      "         sad       0.51      0.48      0.49       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.54      0.54      0.54       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=18...\n",
      "[INFO] k-NN classifier: k=18\n",
      "[INFO] feature accuracy: 54.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.67      0.61       321\n",
      "         sad       0.52      0.41      0.45       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.54      0.54      0.53       600\n",
      "weighted avg       0.54      0.55      0.54       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=19...\n",
      "[INFO] k-NN classifier: k=19\n",
      "[INFO] feature accuracy: 52.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.55      0.60      0.57       321\n",
      "         sad       0.49      0.45      0.47       279\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.52      0.52      0.52       600\n",
      "weighted avg       0.52      0.53      0.52       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=20...\n",
      "[INFO] k-NN classifier: k=20\n",
      "[INFO] feature accuracy: 53.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.65      0.60       321\n",
      "         sad       0.50      0.41      0.45       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.52       600\n",
      "weighted avg       0.53      0.54      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=21...\n",
      "[INFO] k-NN classifier: k=21\n",
      "[INFO] feature accuracy: 53.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.59      0.58       321\n",
      "         sad       0.50      0.47      0.48       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.53       600\n",
      "weighted avg       0.53      0.54      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=22...\n",
      "[INFO] k-NN classifier: k=22\n",
      "[INFO] feature accuracy: 53.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.66      0.60       321\n",
      "         sad       0.50      0.39      0.44       279\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.53      0.53      0.52       600\n",
      "weighted avg       0.53      0.54      0.53       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=23...\n",
      "[INFO] k-NN classifier: k=23\n",
      "[INFO] feature accuracy: 54.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.61      0.59       321\n",
      "         sad       0.52      0.48      0.50       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.55      0.55      0.55       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=24...\n",
      "[INFO] k-NN classifier: k=24\n",
      "[INFO] feature accuracy: 55.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.66      0.61       321\n",
      "         sad       0.52      0.43      0.47       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.55      0.55      0.54       600\n",
      "weighted avg       0.55      0.55      0.55       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=25...\n",
      "[INFO] k-NN classifier: k=25\n",
      "[INFO] feature accuracy: 56.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.58      0.62      0.60       321\n",
      "         sad       0.53      0.49      0.51       279\n",
      "\n",
      "    accuracy                           0.56       600\n",
      "   macro avg       0.56      0.56      0.55       600\n",
      "weighted avg       0.56      0.56      0.56       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=26...\n",
      "[INFO] k-NN classifier: k=26\n",
      "[INFO] feature accuracy: 54.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.56      0.67      0.61       321\n",
      "         sad       0.51      0.40      0.45       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.54      0.54      0.53       600\n",
      "weighted avg       0.54      0.55      0.54       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=27...\n",
      "[INFO] k-NN classifier: k=27\n",
      "[INFO] feature accuracy: 55.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.58      0.64      0.61       321\n",
      "         sad       0.53      0.46      0.49       279\n",
      "\n",
      "    accuracy                           0.56       600\n",
      "   macro avg       0.55      0.55      0.55       600\n",
      "weighted avg       0.55      0.56      0.55       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=28...\n",
      "[INFO] k-NN classifier: k=28\n",
      "[INFO] feature accuracy: 55.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.68      0.62       321\n",
      "         sad       0.52      0.41      0.46       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.55      0.54      0.54       600\n",
      "weighted avg       0.55      0.55      0.54       600\n",
      "\n",
      "[INFO] evaluating feature accuracy for k=29...\n",
      "[INFO] k-NN classifier: k=29\n",
      "[INFO] feature accuracy: 54.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.57      0.64      0.60       321\n",
      "         sad       0.51      0.44      0.47       279\n",
      "\n",
      "    accuracy                           0.55       600\n",
      "   macro avg       0.54      0.54      0.54       600\n",
      "weighted avg       0.54      0.55      0.54       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel2 = None\n",
    "bestAcc2 = 0.0\n",
    "k2 = 0\n",
    "for k in n_neighbors:\n",
    "    print(\"[INFO] evaluating feature accuracy for k={}...\".format(k))\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainFeat, trainLabels)\n",
    "    pred_feat = model.predict(testFeat)\n",
    "    acc = accuracy_score(testLabels, pred_feat)\n",
    "\n",
    "    print(\"[INFO] k-NN classifier: k={}\".format(k))\n",
    "    print(\"[INFO] feature accuracy: {:.2f}%\".format(acc*100))\n",
    "    report = classification_report(testLabels, pred_feat, target_names=[\"happy\", \"sad\"])\n",
    "    print(report)\n",
    "\n",
    "    if acc > bestAcc2:\n",
    "        bestAcc2 = acc\n",
    "        bestModel2 = model\n",
    "        k2 = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"knn_model.sav\"\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best p: 1\n",
      "Best n_neighbors: 18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters)\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(trainFeat, trainLabels)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
