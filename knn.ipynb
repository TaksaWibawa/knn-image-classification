{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]\n",
    "n_neighbors = [3, 5, 7, 9, 11]\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(128, 128)):\n",
    "\treturn cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_features(image):\n",
    "    features = []\n",
    "    for angle in angles:\n",
    "        glcm = graycomatrix(image, [1], [angle], levels=256, symmetric=True, normed=True)\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity')\n",
    "        correlation = graycoprops(glcm, 'correlation')\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')\n",
    "        contrast = graycoprops(glcm, 'contrast')\n",
    "        asm = graycoprops(glcm, 'ASM')\n",
    "        energy = graycoprops(glcm, 'energy')\n",
    "        angle_features = np.concatenate((dissimilarity, correlation, homogeneity, contrast, asm, energy))\n",
    "        features.extend(angle_features)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy    1536\n",
      "sad      1462\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "parent_folder = \"FacialExpression/\"\n",
    "subfolder_names = [\"happy\", \"sad\"]\n",
    "df = pd.DataFrame(columns=['Image Name', 'Category'])\n",
    "\n",
    "df_list = []\n",
    "for subfolder in subfolder_names:\n",
    "    subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "    image_list = os.listdir(subfolder_path)\n",
    "    image_names = [os.path.splitext(image)[0] for image in image_list]\n",
    "    category = [subfolder] * len(image_names)\n",
    "    image_df = pd.DataFrame(\n",
    "        {\"Image Name\": image_names, \"Category\": category})\n",
    "    df_list.append(image_df)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10/2998\n",
      "[INFO] processed 200/2998\n",
      "[INFO] processed 400/2998\n",
      "[INFO] processed 600/2998\n",
      "[INFO] processed 800/2998\n",
      "File corrupted: happy-0974\n",
      "[INFO] processed 1000/2998\n",
      "[INFO] processed 1200/2998\n",
      "[INFO] processed 1400/2998\n",
      "[INFO] processed 1600/2998\n",
      "[INFO] processed 1800/2998\n",
      "[INFO] processed 2000/2998\n",
      "[INFO] processed 2200/2998\n",
      "[INFO] processed 2400/2998\n",
      "File corrupted: sad-0967\n",
      "[INFO] processed 2600/2998\n",
      "[INFO] processed 2800/2998\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(df['Image Name']):\n",
    "    label = imagePath.split(os.path.sep)[-1].split(\"-\")[0]\n",
    "    path = os.path.join(parent_folder, label + '/' + imagePath + \".jpg\")\n",
    "    try:\n",
    "        #read image in grayscale and ersize it to be 1:1\n",
    "        image = cv2.imread(path, 0)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        pixels = image_to_feature_vector(image)\n",
    "        feat = extract_features(image)\n",
    "        rawImages.append(pixels)\n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "    except:\n",
    "        print(\"File corrupted: {}\".format(imagePath))\n",
    "\n",
    "    # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1)% 200 == 0 or i == len(imagePath)-1):\n",
    "\t    print(\"[INFO] processed {}/{}\".format(i+1, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 47.94MB\n",
      "[INFO] features matrix: 0.70MB\n"
     ]
    }
   ],
   "source": [
    "rawImages = np.array(rawImages)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
    "\trawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(\n",
    "\tfeatures.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide 1537 happy and 1463 sad images into equal amount for training and testing using sklearn by 80 20\n",
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "\trawImages, labels, test_size=0.2, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy for k=3...\n",
      "[INFO] k-NN classifier: k=3\n",
      "[INFO] raw pixel accuracy: 61.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.64      0.62      0.63       317\n",
      "         sad       0.59      0.61      0.60       283\n",
      "\n",
      "    accuracy                           0.62       600\n",
      "   macro avg       0.62      0.62      0.62       600\n",
      "weighted avg       0.62      0.62      0.62       600\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=5...\n",
      "[INFO] k-NN classifier: k=5\n",
      "[INFO] raw pixel accuracy: 61.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.65      0.61      0.63       317\n",
      "         sad       0.59      0.63      0.61       283\n",
      "\n",
      "    accuracy                           0.62       600\n",
      "   macro avg       0.62      0.62      0.62       600\n",
      "weighted avg       0.62      0.62      0.62       600\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=7...\n",
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] raw pixel accuracy: 64.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.67      0.66      0.66       317\n",
      "         sad       0.62      0.64      0.63       283\n",
      "\n",
      "    accuracy                           0.65       600\n",
      "   macro avg       0.65      0.65      0.65       600\n",
      "weighted avg       0.65      0.65      0.65       600\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=9...\n",
      "[INFO] k-NN classifier: k=9\n",
      "[INFO] raw pixel accuracy: 64.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.67      0.67      0.67       317\n",
      "         sad       0.63      0.63      0.63       283\n",
      "\n",
      "    accuracy                           0.65       600\n",
      "   macro avg       0.65      0.65      0.65       600\n",
      "weighted avg       0.65      0.65      0.65       600\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy for k=11...\n",
      "[INFO] k-NN classifier: k=11\n",
      "[INFO] raw pixel accuracy: 64.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.67      0.67      0.67       317\n",
      "         sad       0.63      0.62      0.63       283\n",
      "\n",
      "    accuracy                           0.65       600\n",
      "   macro avg       0.65      0.65      0.65       600\n",
      "weighted avg       0.65      0.65      0.65       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel = None\n",
    "bestAcc = 0.0\n",
    "k1 = 0\n",
    "for (i, k) in enumerate(n_neighbors):\n",
    "    print(\"[INFO] evaluating raw pixel accuracy for k={}...\".format(k))\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainRI, trainRL)\n",
    "    pred_raw = model.predict(testRI)\n",
    "    acc = accuracy_score(testRL, pred_raw)\n",
    "\n",
    "    print(\"[INFO] k-NN classifier: k={}\".format(k))\n",
    "    print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc*100))\n",
    "    report = classification_report(testRL, pred_raw, target_names=[\"happy\", \"sad\"])\n",
    "    print(report)\n",
    "\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc\n",
    "        bestModel = model\n",
    "        k1 = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating feature accuracy for k=3...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. KNeighborsClassifier expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[INFO] evaluating feature accuracy for k=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(k))\n\u001b[0;32m      6\u001b[0m model \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39mk)\n\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39;49mfit(trainFeat, trainLabels)\n\u001b[0;32m      8\u001b[0m pred_feat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(testFeat)\n\u001b[0;32m      9\u001b[0m acc \u001b[39m=\u001b[39m accuracy_score(testLabels, pred_feat)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\neighbors\\_classification.py:215\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 215\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\neighbors\\_base.py:454\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 454\u001b[0m         X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    455\u001b[0m             X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    456\u001b[0m         )\n\u001b[0;32m    458\u001b[0m     \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    459\u001b[0m         \u001b[39m# Classification targets require a specific format\u001b[39;00m\n\u001b[0;32m    460\u001b[0m         \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. KNeighborsClassifier expected <= 2."
     ]
    }
   ],
   "source": [
    "bestModel2 = None\n",
    "bestAcc2 = 0.0\n",
    "k2 = 0\n",
    "for k in n_neighbors:\n",
    "    print(\"[INFO] evaluating feature accuracy for k={}...\".format(k))\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainFeat, trainLabels)\n",
    "    pred_feat = model.predict(testFeat)\n",
    "    acc = accuracy_score(testLabels, pred_feat)\n",
    "\n",
    "    print(\"[INFO] k-NN classifier: k={}\".format(k))\n",
    "    print(\"[INFO] feature accuracy: {:.2f}%\".format(acc*100))\n",
    "    report = classification_report(testLabels, pred_feat, target_names=[\"happy\", \"sad\"])\n",
    "    print(report)\n",
    "\n",
    "    if acc > bestAcc2:\n",
    "        bestAcc2 = acc\n",
    "        bestModel2 = model\n",
    "        k2 = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 259\n",
      "320 341\n"
     ]
    }
   ],
   "source": [
    "#check how different between pred_raw and pred_feat\n",
    "\n",
    "count_raw = pred_raw.tolist().count('sad')\n",
    "count_feat = pred_feat.tolist().count('sad')\n",
    "\n",
    "print(count_raw, count_feat)\n",
    "\n",
    "count_raw = pred_raw.tolist().count('happy')\n",
    "count_feat = pred_feat.tolist().count('happy')\n",
    "\n",
    "print(count_raw, count_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] k-NN classifier: k=11\n",
      "[INFO] feature accuracy image model: 64.83%\n",
      "Image 1 is ['happy']\n",
      "Image 2 is ['happy']\n"
     ]
    }
   ],
   "source": [
    "img = \"sad-0031.jpg\"\n",
    "img2 = \"happy-0078.jpg\"\n",
    "img_gray = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2GRAY)\n",
    "img_gray2 = cv2.cvtColor(cv2.imread(img2), cv2.COLOR_BGR2GRAY)\n",
    "feat = image_to_feature_vector(img_gray)\n",
    "feat2 = image_to_feature_vector(img_gray2)\n",
    "\n",
    "pred_img = bestModel.predict([feat])\n",
    "pred_img2 = bestModel.predict([feat2])\n",
    "\n",
    "acc = accuracy_score(testRL, pred_raw)\n",
    "\n",
    "print(\"[INFO] k-NN classifier: k={}\".format(k1))\n",
    "print(\"[INFO] feature accuracy image model: {:.2f}%\".format(acc*100))\n",
    "\n",
    "print(\"Image 1 is {}\".format(pred_img))\n",
    "print(\"Image 2 is {}\".format(pred_img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] k-NN classifier: k=7\n",
      "[INFO] feature accuracy image model: 53.67%\n",
      "Image 1 is ['happy']\n",
      "Image 2 is ['sad']\n"
     ]
    }
   ],
   "source": [
    "img = \"sad-0031.jpg\"\n",
    "img2 = \"happy-0078.jpg\"\n",
    "img_gray = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2GRAY)\n",
    "img_gray2 = cv2.cvtColor(cv2.imread(img2), cv2.COLOR_BGR2GRAY)\n",
    "feat = extract_features(img_gray)\n",
    "feat2 = extract_features(img_gray2)\n",
    "\n",
    "pred_img = bestModel2.predict([feat])\n",
    "pred_img2 = bestModel2.predict([feat2])\n",
    "\n",
    "acc = accuracy_score(testLabels, pred_feat)\n",
    "\n",
    "print(\"[INFO] k-NN classifier: k={}\".format(k2))\n",
    "print(\"[INFO] feature accuracy image model: {:.2f}%\".format(acc*100))\n",
    "\n",
    "print(\"Image 1 is {}\".format(pred_img))\n",
    "print(\"Image 2 is {}\".format(pred_img2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
